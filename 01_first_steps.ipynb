{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "276feb72-4f03-4502-89c9-7379387e864e",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/vischia/adfm_2024-2025/blob/master/01_first_steps.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdeecd8b",
   "metadata": {},
   "source": [
    "# Análisis de Datos en Física Moderna 2024-2025\n",
    "@Pietro Vischia (pietro.vischia@cern.ch)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efddb0c4",
   "metadata": {},
   "source": [
    "This is a jupyter notebook.\n",
    "\n",
    "You can execute the content of a cell by pressing `SHIFT+ENTER`.\n",
    "\n",
    "Cells are of two types:\n",
    "- \"Markdown\": cells like the one you are reading, containing some text or/and images to be displayed.\n",
    "- \"Code\": cells that contain code that needs to be executed.\n",
    "\n",
    "This particular notebook, because of its extension, is a python notebook, therefore the code will have to be in python.\n",
    "\n",
    "In cells of type \"Code\", there are a few special characters that control how a line is run:\n",
    "- By default, the line is passed through the python interpreter\n",
    "- Lines (or portion of lines) starting with `#` are considered comments and are not executed\n",
    "- Lines that start with `!` or `%` are considered shell commands, and are executed as if they were in a terminal (as if you were in the command line where you would normally e.g. run the command `python`).\n",
    "\n",
    "If you are running this in Google Colab, you will need to set up some initial commands in order to be able to use your Google Drive to download data. The next cell is a \"Code\" cell, but it is all commented out. Follow the instructions to set things up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0435f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you are running on Colab:\n",
    "# Uncomment and run the following lines (remove only the \"#\", keep the \"!\").\n",
    "# You can run it anyway, but it will do nothing if you have already installed all dependencies\n",
    "# (and it will take some time to tell you it is not gonna do anything)\n",
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive')\n",
    "#%cd \"/content/drive/MyDrive/\"\n",
    "#! git clone https://github.com/vischia/adfm_2024-2025.git\n",
    "#%cd adfm_2024-2025\n",
    "#%pip install shap torchinfo livelossplot\n",
    "\n",
    "# If you are not running on Colab:\n",
    "# Uncomment and run the following lines, to see what happens\n",
    "#!pwd\n",
    "#!ls\n",
    "#%pip install shap torchinfo livelossplot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b97e0867",
   "metadata": {},
   "source": [
    "### A simple dataset\n",
    "\n",
    "Let's explore a simple dataset: houses in San Francisco and New York. The dataset is available through https://github.com/jadeyee/r2d3-part-1-data ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8081b06b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch the data  \n",
    "!wget https://raw.githubusercontent.com/jadeyee/r2d3-part-1-data/refs/heads/master/part_1_data.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7340fb5e",
   "metadata": {},
   "source": [
    "### Load the data\n",
    "\n",
    "Now the data are on the disk. We need to load them into a readable structure.\n",
    "\n",
    "It is convenient to use the `pandas` library for this, because it loads the data into structures with handy column titles, and it has a lot of utilities to manipulate the data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb9d0d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(\"./part_1_data.csv\", skip_lines=2,sep=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7c45b24",
   "metadata": {},
   "source": [
    "The loading fails. Read the error message, then open the file with an editor to figure out what the issue may be and how to solve it.\n",
    "\n",
    "Hint: you can use the option `skip_lines=...` of `pandas.read_csv()`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1462747f",
   "metadata": {},
   "source": [
    "## Data inspection\n",
    "\n",
    "The first thing you need to do when building a machine learning model is to forget about the model, and **just look at the data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faad07b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf787de7",
   "metadata": {},
   "source": [
    "## Plotting histograms of some observables using matplotlib\n",
    "\n",
    "(see also examples on [matplotlib](https://matplotlib.org/3.5.3/api/_as_gen/matplotlib.pyplot.html) website)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a665318",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "matplotlib.rcParams['figure.figsize'] = (8, 6)\n",
    "matplotlib.rcParams['axes.labelsize'] = 14\n",
    "\n",
    "print(data.columns)\n",
    "plt.hist(data[\"beds\"], bins=100)\n",
    "plt.xlabel(\"Number of beds\")\n",
    "plt.ylabel(\"Events\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02ed1845",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.set()\n",
    "cols_to_plot = [\n",
    "    'Hreco_Lep1_pt',\n",
    "    'Hreco_HadTop_pt',\n",
    "    'Hreco_All5_Jets_pt',\n",
    "    'Hreco_More5_Jets_pt',\n",
    "    'Hreco_Jets_plus_Lep_pt',\n",
    "    'label'\n",
    "]\n",
    "pp=sns.pairplot(data=data, hue='in_sf', diag_kws={'bw_method': 0.2})\n",
    "pp.map_lower(sns.kdeplot, levels=4, color=\".2\") # Contours\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe23c65a",
   "metadata": {},
   "source": [
    "### Split the data set into training and test set\n",
    "\n",
    "When we train a machine learning algorithm, we are trying to solve an interpolation problem (*find the function of the input features that provides the best approximation of the true function*) by also requiring that the solution generalizes sufficiently well (*the interpolating function must also predict correctly the value of the true function for new, unseen data*).\n",
    "\n",
    "\n",
    "When we have a labelled dataset, we will therefore split it into: a *training set*, which we will use to train the machine learning algorithm; a *test set*, which we will use to evaluate the performance of the algorithm for various realizations of the algorithm (e.g. tuning hyperparameters); and an *application set*, which are the data we are really interested in studying in the end.\n",
    "\n",
    "For many applications, when the amount of hyperparameters tuning is moderate, application set and test set can be collapsed into a single set (usually called *test set*). This is what we will do in this tutorial.\n",
    "\n",
    "![Blah](figs/trainingNetwork.png)\n",
    "\n",
    "(Image: P. Vischia, [doi:10.5281/zenodo.6373442](https://doi.org/10.5281/zenodo.6373442))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "890a4344",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import roc_curve, auc, accuracy_score\n",
    "from sklearn.tree import export_graphviz\n",
    "from sklearn.inspection import permutation_importance\n",
    "try:\n",
    "    # See #1137: this allows compatibility for scikit-learn >= 0.24\n",
    "    from sklearn.utils import safe_indexing\n",
    "except ImportError:\n",
    "    from sklearn.utils import _safe_indexing\n",
    "import numpy as np    \n",
    "    \n",
    "X = data.drop([\"in_sf\"], axis=1)\n",
    "y = data[\"in_sf\"]\n",
    "\n",
    "\n",
    "import sklearn\n",
    "X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "\n",
    "print(f\"We have {len(X_train)} training samples with {sum(y_train)} signal and {sum(1-y_train)} background events\")\n",
    "print(f\"We have {len(X_test)} testing samples with {sum(y_test)} signal and {sum(1-y_test)} background events\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d1dca5e",
   "metadata": {},
   "source": [
    "Now we will choose a simple criterion, for instance the value of one of the features that characterize the houses, and use it to decide if the house is in New York (we want to predict `0`) or in San Francisco (we want to predict `1`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33097a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X, var, val):\n",
    "    pred = X[var]\n",
    "    return np.array([0 if p > val  else 1 for p in pred])\n",
    "\n",
    "    \n",
    "def score(myX, myY, var, val):\n",
    "    return accuracy_score(myY, predict(myX, var, val))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f93d1398",
   "metadata": {},
   "source": [
    "Let's try a few of them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cca703a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tested_var=\"price\"\n",
    "threshold_val=100000 # dollars\n",
    "print('Personalised score: train accuracy', score(X_train, y_train, tested_var, threshold_val), ', test accuracy', score(X_test, y_test, tested_var, threshold_val))\n",
    "threshold_val=1000000 # dollars\n",
    "print('Personalised score: train accuracy', score(X_train, y_train, tested_var, threshold_val), ', test accuracy', score(X_test, y_test, tested_var, threshold_val))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b501855a",
   "metadata": {},
   "source": [
    "Now let's try out a \"thresholding on steroids\" machine learning classifier, called Boosted Decision Tree (BDT), and compare its accuracy with the personalised score one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0b88bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "\n",
    "learning_rate = 1.0\n",
    "\n",
    "bdt_ada = AdaBoostClassifier(estimator=DecisionTreeClassifier(max_depth=3, criterion='log_loss'), n_estimators=100, learning_rate=learning_rate, random_state=42)\n",
    "fitted_bdt_ada=bdt_ada.fit(X_train, y_train)\n",
    "\n",
    "tested_var=\"price\"\n",
    "threshold_val=1000000 # dollars\n",
    "\n",
    "print('Adaptive boost: train accuracy', fitted_bdt_ada.score(X_train, y_train),', test accuracy', fitted_bdt_ada.score(X_test, y_test))\n",
    "print('Personalised score: train accuracy', score(X_train, y_train, tested_var, threshold_val), ', test accuracy', score(X_test, y_test, tested_var, threshold_val))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d7bb78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a066f740",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_rocs(scores_and_names, y):\n",
    "    pack=[] \n",
    "    for s, n in scores_and_names: \n",
    "        fpr, tpr, thresholds = roc_curve(y.ravel(), s)\n",
    "        pack.append([n, fpr,tpr,thresholds])\n",
    "\n",
    "    plt.figure()\n",
    "    lw=2\n",
    "    for n, fpr, tpr, thresholds in pack:\n",
    "        plt.plot(fpr, tpr, lw=lw, label=\"%s (AUC = %0.2f)\" % (n, auc(fpr, tpr))) \n",
    "\n",
    "    plt.plot([0, 1], [0, 1], color=\"navy\", lw=lw, linestyle=\"--\")\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel(\"False Positive Rate\")\n",
    "    plt.ylabel(\"True Positive Rate\")\n",
    "    plt.title(\"Receiver Operating Characteristic curve\")\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "def decision_function(myX, myY, var, val):\n",
    "    #pred=predict(myX, var, val)\n",
    "    pred=myX[var]\n",
    "    #pred=(pred-pred.min())/(pred.max()-pred.min())\n",
    "    return -pred\n",
    "\n",
    "y_score = fitted_bdt_ada.decision_function(X_test)\n",
    "plot_rocs([ [fitted_bdt_ada.decision_function(X_test), 'AdaBoost'],\n",
    "            [decision_function(X_test, y_test, tested_var, threshold_val), 'Personalised score']],\n",
    "          y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a4ae33",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
